{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12229465,"sourceType":"datasetVersion","datasetId":7705304}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd\nimport numpy as np\nimport math\n\n# Dataset: multivariate input, univariate target (next Global_active_power)\nclass TimeSeriesDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, seq_length: int, target_col: str):\n        # df: DataFrame với datetime index, các cột features\n        self.features = df.values.astype('float32')\n        self.seq_length = seq_length\n        self.target_idx = df.columns.get_loc(target_col)\n\n    def __len__(self):\n        return len(self.features) - self.seq_length\n\n    def __getitem__(self, idx):\n        x = self.features[idx : idx + self.seq_length]            # (seq_length, num_features)\n        y = self.features[idx + self.seq_length, self.target_idx] # scalar\n        return torch.from_numpy(x), torch.tensor(y, dtype=torch.float32)\n\n# Positional encoding for Transformer\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n        pe = torch.zeros(max_len, d_model)\n        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(1)  # (max_len, 1, d_model)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        # x: (seq_len, batch, d_model)\n        x = x + self.pe[:x.size(0)]\n        return x\n\n# Transformer-based model for time series forecasting\nclass TransformerModel(nn.Module):\n    def __init__(\n        self,\n        input_size: int,\n        d_model: int = 64,\n        nhead: int = 4,\n        num_layers: int = 2,\n        dim_feedforward: int = 128,\n        dropout: float = 0.1,\n    ):\n        super().__init__()\n        # Map input features to d_model dimension\n        self.input_fc = nn.Linear(input_size, d_model)\n        # Positional encoding\n        self.pos_encoder = PositionalEncoding(d_model)\n        # Transformer encoder\n        encoder_layer = nn.TransformerEncoderLayer(\n            d_model=d_model,\n            nhead=nhead,\n            dim_feedforward=dim_feedforward,\n            dropout=dropout,\n            batch_first=False,\n        )\n        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n        # Final projection to scalar output\n        self.decoder = nn.Linear(d_model, 1)\n\n    def forward(self, x):\n        # x: (batch, seq_len, input_size)\n        # 1) project to d_model\n        x = self.input_fc(x)            # (batch, seq_len, d_model)\n        # 2) prepare for transformer: (seq_len, batch, d_model)\n        x = x.permute(1, 0, 2)\n        # 3) add positional encoding\n        x = self.pos_encoder(x)\n        # 4) transformer encode\n        output = self.transformer_encoder(x)  # (seq_len, batch, d_model)\n        # 5) take last time step's representation\n        last = output[-1, :, :]               # (batch, d_model)\n        # 6) decode to scalar\n        y = self.decoder(last)                # (batch, 1)\n        return y.squeeze(-1)                  # (batch,)\n\n# Training function\ndef train(model, dataloader, criterion, optimizer, epochs, device):\n    model.to(device)\n    for epoch in range(1, epochs + 1):\n        model.train()\n        total_loss = 0.0\n        for x_batch, y_batch in dataloader:\n            x_batch = x_batch.to(device)\n            y_batch = y_batch.to(device)\n            optimizer.zero_grad()\n            preds = model(x_batch)\n            loss = criterion(preds, y_batch)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        avg_loss = total_loss / len(dataloader)\n        print(f\"Epoch {epoch}/{epochs}, Loss: {avg_loss:.6f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:30:45.414777Z","iopub.execute_input":"2025-06-21T13:30:45.415562Z","iopub.status.idle":"2025-06-21T13:30:47.497811Z","shell.execute_reply.started":"2025-06-21T13:30:45.415527Z","shell.execute_reply":"2025-06-21T13:30:47.497228Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Giả lập df_new tương tự cấu trúc thực tế\ndf_new = pd.read_csv(\"/kaggle/input/clean-ts/clean.csv\")\ndf_new['dt'] = pd.to_datetime(df_new['dt'])\ndf_new.set_index('dt', inplace=True)\n\n# Hyperparameters\nseq_length = 7\nbatch_size = 50000\nd_model = 96\nnhead = 4\nnum_layers = 2\ndim_feedforward = 128\nlearning_rate = 1e-3\nepochs = 20\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Dataset & DataLoader\ndataset = TimeSeriesDataset(df_new, seq_length, target_col='Global_active_power')\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n\n# Model, loss, optimizer\nmodel = TransformerModel(\n    input_size=df_new.shape[1],\n    d_model=d_model,\n    nhead=nhead,\n    num_layers=num_layers,\n    dim_feedforward=dim_feedforward,\n    dropout=0.1,\n)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n# Train\ntrain(model, dataloader, criterion, optimizer, epochs, device)\n\n# Save weights\ntorch.save(model.state_dict(), 'transformer_model.pth')\nprint(\"Transformer model saved to transformer_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-21T13:30:48.949026Z","iopub.execute_input":"2025-06-21T13:30:48.949739Z","iopub.status.idle":"2025-06-21T13:30:57.487346Z","shell.execute_reply.started":"2025-06-21T13:30:48.949712Z","shell.execute_reply":"2025-06-21T13:30:57.486240Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"    loaded = TransformerModel(\n        input_size=df_new.shape[1], d_model=d_model,\n        nhead=nhead, num_layers=num_layers,\n        dim_feedforward=dim_feedforward\n    )\n    loaded.load_state_dict(torch.load('transformer_model.pth', map_location=device))\n    loaded.to(device).eval()\n\n    n_samples = 200\n    y_true, y_pred = [], []\n    with torch.no_grad():\n        for idx in range(len(dataset) - n_samples, len(dataset)):\n            x, y = dataset[idx]\n            x = x.unsqueeze(0).to(device)\n            pred = loaded(x)\n            y_true.append(y.item())\n            y_pred.append(pred.item())\n\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    mse = np.mean((y_true - y_pred) ** 2)\n    mae = np.mean(np.abs(y_true - y_pred))\n    print(f\"MSE over {n_samples} samples: {mse:.6f}\")\n    print(f\"MAE over {n_samples} samples: {mae:.6f}\")\n\n    # Vẽ biểu đồ so sánh\n    plt.figure(figsize=(10, 5))\n    plt.plot(y_true, label='Actual')\n    plt.plot(y_pred, label='Predicted')\n    plt.title('Actual vs Predicted Global_active_power (Transformer)')\n    plt.xlabel('Sample Index')\n    plt.ylabel('Global_active_power')\n    plt.legend()\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}